{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import struct\n",
    "from collections import  defaultdict\n",
    "\n",
    "from transformers import T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exponent(model, nbits):\n",
    "    exponent = {}\n",
    "    for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "        # assert param.dtype is torch.float16\n",
    "        if param.ndim == 2 and param.shape[0] != 1 and param.shape[1] != 1:\n",
    "            r, c = param.shape\n",
    "            tensor_data = list(\n",
    "                map(lambda x: int(\n",
    "                        \"{}\".format(\n",
    "                                bin(\n",
    "                                    int.from_bytes(\n",
    "                                    struct.pack('>e', x), byteorder='big'\n",
    "                                    )\n",
    "                                )[3: 3+nbits]      # torch.float16 [3: 8] torch.bfloat16[3: 11]\n",
    "                            ), \n",
    "                            base=2\n",
    "                    ),\n",
    "                    param.abs().neg().reshape(-1).tolist()\n",
    "                )\n",
    "            )\n",
    "            tensor = torch.tensor(tensor_data, dtype=torch.int8).reshape(r, c)\n",
    "            exponent[name] = tensor\n",
    "    return exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the exponent ###\n",
    "models_hub = {\n",
    "    \"t5\": {\n",
    "        \"path\": \"/home/styaeng/project/delta-compress/pretrained_model/t5\",       ### 这里要写成下载后的模型权重文件所在的路径\n",
    "        \"hdlr\": T5ForConditionalGeneration.from_pretrained\n",
    "    }\n",
    "}\n",
    "t5_model = models_hub['t5']['hdlr'](models_hub['t5']['path'])\n",
    "t5_exponent = get_exponent(t5_model, nbits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2 bits\n",
    "    [0 | 1 | 2 | 3]\n",
    "3 bits\n",
    "    [0 | 1 | 2 | 3 | 4 | 5 | 6 | 7]\n",
    "4 bits\n",
    "    [0-15]\n",
    "5 bits\n",
    "    [0]\n",
    "'''\n",
    "\n",
    "pattern = [\n",
    "    [0, 1, 2, 3],\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    [0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the percentage in matrix granularity ###\n",
    "tensor_pattern = []\n",
    "for k, v in t5_exponent.items():\n",
    "    tensor_self_pattern = defaultdict(dict)\n",
    "    tensor_self_pattern['name'] = k\n",
    "    row, col = v.shape\n",
    "    tensor_self_pattern['size'] = v.numel()\n",
    "    t = v\n",
    "    for shift in range(3, -1, -1):\n",
    "        idx = 3 - shift\n",
    "        pat = pattern[idx]\n",
    "        tmp = t >> shift\n",
    "        tensor_self_pattern[f'{idx+2}_bits'] = {}\n",
    "        for elem in pat:\n",
    "            tensor_self_pattern[f\"{idx+2}_bits\"][elem] = torch.count_nonzero(tmp == elem)\n",
    "        # tensor_self_pattern['compress_num'][value] = torch.count_nonzero(t == value) / (row * col)\n",
    "    tensor_pattern.append(tensor_self_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight \t 2510 \t 1359 \t 3 \t 45.86%\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight \t -1 \t -1 \t -1 \t -100.00%\n",
      "encoder.block.0.layer.1.DenseReluDense.wi.weight \t 160 \t 82 \t 3 \t 48.75%\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight \t 160 \t 91 \t 4 \t 43.12%\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.1.layer.1.DenseReluDense.wi.weight \t 160 \t 80 \t 3 \t 50.00%\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight \t 160 \t 93 \t 4 \t 41.88%\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.2.layer.1.DenseReluDense.wi.weight \t 160 \t 80 \t 3 \t 50.00%\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight \t 160 \t 94 \t 3 \t 41.25%\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "encoder.block.3.layer.1.DenseReluDense.wi.weight \t 160 \t 80 \t 3 \t 50.00%\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight \t 160 \t 93 \t 3 \t 41.88%\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "encoder.block.4.layer.1.DenseReluDense.wi.weight \t 160 \t 80 \t 3 \t 50.00%\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight \t 160 \t 92 \t 3 \t 42.50%\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight \t 40 \t 24 \t 3 \t 40.00%\n",
      "encoder.block.5.layer.1.DenseReluDense.wi.weight \t 160 \t 81 \t 3 \t 49.38%\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight \t 160 \t 92 \t 3 \t 42.50%\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight \t -1 \t -1 \t -1 \t -100.00%\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "decoder.block.0.layer.2.DenseReluDense.wi.weight \t 160 \t 82 \t 3 \t 48.75%\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight \t 160 \t 92 \t 4 \t 42.50%\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight \t 40 \t 23 \t 4 \t 42.50%\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "decoder.block.1.layer.2.DenseReluDense.wi.weight \t 160 \t 80 \t 3 \t 50.00%\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight \t 160 \t 92 \t 4 \t 42.50%\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight \t 40 \t 24 \t 3 \t 40.00%\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.2.layer.2.DenseReluDense.wi.weight \t 160 \t 80 \t 3 \t 50.00%\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight \t 160 \t 93 \t 4 \t 41.88%\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight \t 40 \t 24 \t 3 \t 40.00%\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.3.layer.2.DenseReluDense.wi.weight \t 160 \t 81 \t 3 \t 49.38%\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight \t 160 \t 93 \t 3 \t 41.88%\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight \t 40 \t 24 \t 3 \t 40.00%\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.4.layer.2.DenseReluDense.wi.weight \t 160 \t 80 \t 3 \t 50.00%\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight \t 160 \t 93 \t 3 \t 41.88%\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight \t 40 \t 20 \t 3 \t 50.00%\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight \t 40 \t 22 \t 3 \t 45.00%\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight \t 40 \t 21 \t 3 \t 47.50%\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight \t 40 \t 24 \t 3 \t 40.00%\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight \t 40 \t 24 \t 3 \t 40.00%\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight \t 40 \t 23 \t 3 \t 42.50%\n",
      "decoder.block.5.layer.2.DenseReluDense.wi.weight \t 160 \t 80 \t 3 \t 50.00%\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight \t 160 \t 92 \t 3 \t 42.50%\n",
      "compression_ratio = 42.76%\n"
     ]
    }
   ],
   "source": [
    "bitwid = 5\n",
    "compress_bit = 2\n",
    "tensor_id = 1\n",
    "PageSize = 4 * 1024 * 8\n",
    "\n",
    "compression_ratio_average = 0\n",
    "for tensor_id in range(0, len(tensor_pattern)):\n",
    "    final_compression_ratio = -1\n",
    "    final_bitwise = -1\n",
    "    before_compress_bit = tensor_pattern[tensor_id]['size'] * 5\n",
    "    final_compressed_page_count = -1\n",
    "    final_uncompressed_page_count = -1\n",
    "    for compress_bit in range(2, 6):\n",
    "        compress_cnt = torch.tensor(list(tensor_pattern[tensor_id][f'{compress_bit}_bits'].values())).max().item()\n",
    "        \n",
    "        compressed_part = compress_cnt * (bitwid - compress_bit) + compress_bit\n",
    "        uncompressed_part = (tensor_pattern[tensor_id]['size'] - compress_cnt) * 5\n",
    "\n",
    "        compressed_page_count = (compressed_part + PageSize - 1) // PageSize + (uncompressed_part + PageSize - 1) // PageSize\n",
    "        uncompressed_page_count = (before_compress_bit + PageSize - 1) // PageSize\n",
    "        compression_ratio = (uncompressed_page_count - compressed_page_count) / uncompressed_page_count\n",
    "\n",
    "        if final_compression_ratio < compression_ratio:\n",
    "            final_compression_ratio = compression_ratio\n",
    "            final_bitwise = compress_bit\n",
    "            final_compressed_page_count = compressed_page_count\n",
    "            final_uncompressed_page_count = uncompressed_page_count\n",
    "    compression_ratio_average += final_compression_ratio / len(tensor_pattern)\n",
    "    print(f\"{tensor_pattern[tensor_id]['name']}\", \\\n",
    "            \"\\t\", final_uncompressed_page_count, \\\n",
    "            \"\\t\", final_compressed_page_count, \\\n",
    "            \"\\t\", final_bitwise, \\\n",
    "            \"\\t\", f\"{final_compression_ratio * 100:.2f}%\")\n",
    "print(f\"compression_ratio = {compression_ratio_average * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Get the percentage in tile granularity ###\n",
    "tensor_pattern_tile_gran = []\n",
    "for k, v in t5_exponent.items():\n",
    "    tensor_self_pattern = defaultdict(dict)\n",
    "    tensor_self_pattern[\"name\"] = k\n",
    "    row, col = v.shape\n",
    "    t = v\n",
    "    for row_id in range(t.shape[0]):\n",
    "        tensor_self_pattern[f\"row_{row_id}\"]['size'] = t[row_id].numel()\n",
    "        for shift in range(3, -1, -1):\n",
    "            idx = 3 - shift\n",
    "            pat = pattern[idx]\n",
    "            tmp = t[row_id] >> shift\n",
    "            tensor_self_pattern[f\"row_{row_id}\"][f'{idx+2}_bits'] = {}\n",
    "            for elem in pat:\n",
    "                tensor_self_pattern[f\"row_{row_id}\"][f\"{idx+2}_bits\"][elem] = torch.count_nonzero(tmp == elem)\n",
    "    tensor_pattern_tile_gran.append(tensor_self_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: tensor(1),\n",
       " 1: tensor(0),\n",
       " 2: tensor(0),\n",
       " 3: tensor(0),\n",
       " 4: tensor(5),\n",
       " 5: tensor(15),\n",
       " 6: tensor(58),\n",
       " 7: tensor(219),\n",
       " 8: tensor(182),\n",
       " 9: tensor(24),\n",
       " 10: tensor(5),\n",
       " 11: tensor(2),\n",
       " 12: tensor(1),\n",
       " 13: tensor(0),\n",
       " 14: tensor(0),\n",
       " 15: tensor(0)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_pattern_tile_gran[0]['row_0']['4_bits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   0,   0,   0,   5,  15,  58, 219, 182,  24,   5,   2,   1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bincount(t5_exponent[tensor_pattern_tile_gran[0]['name']][0] >> 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight \t 2510 \t 4 \t 5 \t 99.84%\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight \t 1 \t 2 \t 5 \t -100.00%\n",
      "encoder.block.0.layer.1.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.1.layer.1.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.2.layer.1.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.3.layer.1.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.4.layer.1.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "encoder.block.5.layer.1.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight \t 1 \t 2 \t 5 \t -100.00%\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.0.layer.2.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.1.layer.2.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.2.layer.2.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.3.layer.2.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.4.layer.2.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight \t 40 \t 2 \t 5 \t 95.00%\n",
      "decoder.block.5.layer.2.DenseReluDense.wi.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight \t 160 \t 2 \t 5 \t 98.75%\n",
      "compression_ratio = 92.02%\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(t5_exponent.items()):\n",
    "    assert tensor_pattern_tile_gran[i]['name'] == k\n",
    "    for row_id in range(v.shape[0]):\n",
    "        assert tensor_pattern_tile_gran[i][f'row_{row_id}']['size'] == v.shape[1]\n",
    "        for bit_count in range(2, 5):\n",
    "            assert torch.tensor(\n",
    "                list(\n",
    "                    tensor_pattern_tile_gran[i][f'row_{row_id}'][f'{bit_count}_bits'].values()\n",
    "                    )\n",
    "                ).sum() == v.shape[1]\n",
    "\n",
    "bitwid = 5\n",
    "compress_bit = 2\n",
    "tensor_id = 1\n",
    "PageSize = 4 * 1024 * 8\n",
    "\n",
    "compression_ratio_average = 0\n",
    "for tensor_id in range(0, len(tensor_pattern_tile_gran)):\n",
    "    final_compression_ratio = -1\n",
    "    final_pages = 0\n",
    "    t = t5_exponent[tensor_pattern_tile_gran[tensor_id]['name']]\n",
    "    row, col = t.shape\n",
    "    origin_pages = 0\n",
    "    compressed_tensor_bits = 0\n",
    "    uncompressed_tensor_bits = 0\n",
    "    bits_of_tensor = 0\n",
    "    for row_id in range(row):\n",
    "        compressed_part = 0\n",
    "        uncompressed_part = 0\n",
    "        max_compression_ratio = -1\n",
    "        max_bits = -1\n",
    "        final_bits = []\n",
    "        before_compress_bits = tensor_pattern_tile_gran[tensor_id][f\"row_{row_id}\"]['size'] * 5\n",
    "        for bit_idx in range(2, 6):\n",
    "            compress_cnt = torch.tensor(\n",
    "                list(\n",
    "                    tensor_pattern_tile_gran[tensor_id][f\"row_{row_id}\"][f\"{bit_idx}_bits\"].values()\n",
    "                    )\n",
    "                ).max().item()\n",
    "            compressed_bit = compress_cnt * (bitwid - bit_idx) + bit_idx\n",
    "            uncompressed_bit = (tensor_pattern_tile_gran[tensor_id][f\"row_{row_id}\"]['size'] - compress_cnt) * 5\n",
    "            compression_ratio = (before_compress_bits - compress_bit + uncompressed_bit) / before_compress_bits\n",
    "            if max_compression_ratio < compression_ratio:\n",
    "                max_bits = bit_idx\n",
    "                final_bits = [compress_bit , uncompressed_bit]\n",
    "        compressed_tensor_bits += final_bits[0]\n",
    "        uncompressed_tensor_bits += final_bits[1]\n",
    "        bits_of_tensor += tensor_pattern_tile_gran[tensor_id][f\"row_{row_id}\"]['size'] * 5\n",
    "    final_pages = (compressed_tensor_bits + PageSize - 1) // PageSize + (compressed_tensor_bits + PageSize - 1) // PageSize\n",
    "    origin_pages = (bits_of_tensor + PageSize - 1) // PageSize\n",
    "    final_compression_ratio = (origin_pages - final_pages) / origin_pages\n",
    "    compression_ratio_average += (final_compression_ratio / len(tensor_pattern_tile_gran))\n",
    "    print(f\"{tensor_pattern_tile_gran[tensor_id]['name']}\", \\\n",
    "            \"\\t\", origin_pages, \\\n",
    "            \"\\t\", final_pages, \\\n",
    "            \"\\t\", max_bits, \\\n",
    "            \"\\t\", f\"{final_compression_ratio * 100:.2f}%\")\n",
    "print(f\"compression_ratio = {compression_ratio_average * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "print((t[0:512].numel() * 5 + PageSize - 1) // PageSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PageSize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m     after_compressed_bits \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (compressed_bits \u001b[38;5;241m+\u001b[39m uncompressed_bits)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# print(compressed_bits, uncompressed_bits, original_bits)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# original_pages = (origin_bits + PageSize - 1) // PageSize\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# after_compressed_pages = (compressed_bits + PageSize - 1) // PageSize \\\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#     + (uncompressed_bits + PageSize - 1) // PageSize\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# print(after_compressed_pages, original_pages)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m origin_pages \u001b[38;5;241m=\u001b[39m (original_bits \u001b[38;5;241m+\u001b[39m \u001b[43mPageSize\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m PageSize\n\u001b[1;32m     17\u001b[0m after_compressed_pages \u001b[38;5;241m=\u001b[39m (after_compressed_bits \u001b[38;5;241m+\u001b[39m PageSize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m PageSize\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(origin_pages, after_compressed_pages)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PageSize' is not defined"
     ]
    }
   ],
   "source": [
    "original_bits = 0\n",
    "after_compressed_bits = 0\n",
    "for row in t[0:512]:\n",
    "    max_count = torch.bincount(row).max().item()\n",
    "    max_idx = torch.log2(torch.bincount(row).argmax())\n",
    "    max_bit = torch.ceil(max_idx).to(torch.uint8).item()\n",
    "    compressed_bits = max_count * (5 - 4) + 4\n",
    "    uncompressed_bits = (row.shape[0] - max_count) * 5\n",
    "    original_bits += row.shape[0] * 5\n",
    "    after_compressed_bits += (compressed_bits + uncompressed_bits)\n",
    "    # print(compressed_bits, uncompressed_bits, original_bits)\n",
    "    # original_pages = (origin_bits + PageSize - 1) // PageSize\n",
    "    # after_compressed_pages = (compressed_bits + PageSize - 1) // PageSize \\\n",
    "    #     + (uncompressed_bits + PageSize - 1) // PageSize\n",
    "    # print(after_compressed_pages, original_pages)\n",
    "origin_pages = (original_bits + PageSize - 1) // PageSize\n",
    "after_compressed_pages = (after_compressed_bits + PageSize - 1) // PageSize\n",
    "print(origin_pages, after_compressed_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
